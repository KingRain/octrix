import type {
  Cluster,
  Node,
  Pod,
  Service,
  Deployment,
  Namespace,
  HealingRule,
  HealingEvent,
  SimulationScenario,
  SimulationRun,
  Alert,
  MetricDataPoint,
} from "@/types";

function generateTimeSeriesData(
  hours: number,
  baseValue: number,
  variance: number
): MetricDataPoint[] {
  const data: MetricDataPoint[] = [];
  const now = new Date();
  for (let i = hours * 60; i >= 0; i -= 5) {
    const timestamp = new Date(now.getTime() - i * 60 * 1000);
    const value = baseValue + (Math.random() - 0.5) * variance;
    data.push({
      timestamp: timestamp.toISOString(),
      value: Math.max(0, Math.min(100, value)),
    });
  }
  return data;
}

export const mockClusters: Cluster[] = [
  {
    id: "cluster-1",
    name: "production-us-east",
    status: "healthy",
    version: "1.28.4",
    nodeCount: 12,
    podCount: 156,
    serviceCount: 24,
    cpuUsage: 67,
    memoryUsage: 72,
    createdAt: "2024-01-15T10:30:00Z",
    region: "us-east-1",
    provider: "aws",
  },
  {
    id: "cluster-2",
    name: "staging-eu-west",
    status: "warning",
    version: "1.28.4",
    nodeCount: 6,
    podCount: 78,
    serviceCount: 18,
    cpuUsage: 45,
    memoryUsage: 58,
    createdAt: "2024-02-20T14:15:00Z",
    region: "eu-west-1",
    provider: "aws",
  },
  {
    id: "cluster-3",
    name: "dev-us-west",
    status: "healthy",
    version: "1.29.0",
    nodeCount: 4,
    podCount: 42,
    serviceCount: 12,
    cpuUsage: 32,
    memoryUsage: 41,
    createdAt: "2024-03-10T08:00:00Z",
    region: "us-west-2",
    provider: "aws",
  },
];

export const mockNodes: Node[] = [
  {
    id: "node-1",
    name: "ip-10-0-1-101.ec2.internal",
    status: "ready",
    role: "control-plane",
    cpuCapacity: 8000,
    cpuUsage: 2400,
    memoryCapacity: 32768,
    memoryUsage: 18432,
    podCount: 12,
    conditions: [
      {
        type: "Ready",
        status: "True",
        reason: "KubeletReady",
        message: "kubelet is posting ready status",
        lastTransitionTime: "2024-01-15T10:30:00Z",
      },
    ],
    labels: {
      "node-role.kubernetes.io/control-plane": "",
      "kubernetes.io/os": "linux",
    },
    taints: [
      {
        key: "node-role.kubernetes.io/control-plane",
        value: "",
        effect: "NoSchedule",
      },
    ],
    createdAt: "2024-01-15T10:30:00Z",
    ip: "10.0.1.101",
  },
  {
    id: "node-2",
    name: "ip-10-0-1-102.ec2.internal",
    status: "ready",
    role: "worker",
    cpuCapacity: 16000,
    cpuUsage: 12800,
    memoryCapacity: 65536,
    memoryUsage: 52428,
    podCount: 28,
    conditions: [
      {
        type: "Ready",
        status: "True",
        reason: "KubeletReady",
        message: "kubelet is posting ready status",
        lastTransitionTime: "2024-01-15T10:35:00Z",
      },
    ],
    labels: {
      "node-role.kubernetes.io/worker": "",
      "kubernetes.io/os": "linux",
      "topology.kubernetes.io/zone": "us-east-1a",
    },
    taints: [],
    createdAt: "2024-01-15T10:35:00Z",
    ip: "10.0.1.102",
  },
  {
    id: "node-3",
    name: "ip-10-0-1-103.ec2.internal",
    status: "ready",
    role: "worker",
    cpuCapacity: 16000,
    cpuUsage: 9600,
    memoryCapacity: 65536,
    memoryUsage: 45875,
    podCount: 24,
    conditions: [
      {
        type: "Ready",
        status: "True",
        reason: "KubeletReady",
        message: "kubelet is posting ready status",
        lastTransitionTime: "2024-01-15T10:40:00Z",
      },
    ],
    labels: {
      "node-role.kubernetes.io/worker": "",
      "kubernetes.io/os": "linux",
      "topology.kubernetes.io/zone": "us-east-1b",
    },
    taints: [],
    createdAt: "2024-01-15T10:40:00Z",
    ip: "10.0.1.103",
  },
  {
    id: "node-4",
    name: "ip-10-0-1-104.ec2.internal",
    status: "not-ready",
    role: "worker",
    cpuCapacity: 16000,
    cpuUsage: 0,
    memoryCapacity: 65536,
    memoryUsage: 0,
    podCount: 0,
    conditions: [
      {
        type: "Ready",
        status: "False",
        reason: "KubeletNotReady",
        message: "container runtime network not ready",
        lastTransitionTime: "2024-01-20T15:30:00Z",
      },
    ],
    labels: {
      "node-role.kubernetes.io/worker": "",
      "kubernetes.io/os": "linux",
      "topology.kubernetes.io/zone": "us-east-1c",
    },
    taints: [
      {
        key: "node.kubernetes.io/not-ready",
        value: "",
        effect: "NoSchedule",
      },
    ],
    createdAt: "2024-01-15T10:45:00Z",
    ip: "10.0.1.104",
  },
];

export const mockPods: Pod[] = [
  {
    id: "pod-1",
    name: "api-gateway-7d8f9c6b5-x2k4m",
    namespace: "production",
    status: "running",
    phase: "Running",
    nodeName: "ip-10-0-1-102.ec2.internal",
    containers: [
      {
        name: "api-gateway",
        image: "octrix/api-gateway:v2.1.0",
        status: "running",
        ready: true,
        restartCount: 0,
        cpuUsage: 250,
        memoryUsage: 512,
        ports: [{ name: "http", containerPort: 8080, protocol: "TCP" }],
      },
    ],
    restarts: 0,
    cpuUsage: 250,
    memoryUsage: 512,
    createdAt: "2024-01-18T09:00:00Z",
    labels: { app: "api-gateway", version: "v2.1.0" },
    annotations: {},
    ownerReferences: [{ kind: "ReplicaSet", name: "api-gateway-7d8f9c6b5", uid: "rs-1" }],
    ip: "10.244.1.15",
  },
  {
    id: "pod-2",
    name: "user-service-5c7d8e9f1-a3b2c",
    namespace: "production",
    status: "running",
    phase: "Running",
    nodeName: "ip-10-0-1-102.ec2.internal",
    containers: [
      {
        name: "user-service",
        image: "octrix/user-service:v1.8.2",
        status: "running",
        ready: true,
        restartCount: 2,
        cpuUsage: 180,
        memoryUsage: 384,
        ports: [{ name: "grpc", containerPort: 9090, protocol: "TCP" }],
      },
    ],
    restarts: 2,
    cpuUsage: 180,
    memoryUsage: 384,
    createdAt: "2024-01-18T09:05:00Z",
    labels: { app: "user-service", version: "v1.8.2" },
    annotations: {},
    ownerReferences: [{ kind: "ReplicaSet", name: "user-service-5c7d8e9f1", uid: "rs-2" }],
    ip: "10.244.1.16",
  },
  {
    id: "pod-3",
    name: "order-processor-8e9f0a1b2-d4e5f",
    namespace: "production",
    status: "running",
    phase: "Running",
    nodeName: "ip-10-0-1-103.ec2.internal",
    containers: [
      {
        name: "order-processor",
        image: "octrix/order-processor:v3.0.1",
        status: "running",
        ready: true,
        restartCount: 0,
        cpuUsage: 420,
        memoryUsage: 768,
        ports: [{ name: "http", containerPort: 8080, protocol: "TCP" }],
      },
    ],
    restarts: 0,
    cpuUsage: 420,
    memoryUsage: 768,
    createdAt: "2024-01-18T09:10:00Z",
    labels: { app: "order-processor", version: "v3.0.1" },
    annotations: {},
    ownerReferences: [{ kind: "ReplicaSet", name: "order-processor-8e9f0a1b2", uid: "rs-3" }],
    ip: "10.244.2.22",
  },
  {
    id: "pod-4",
    name: "payment-service-2a3b4c5d6-g7h8i",
    namespace: "production",
    status: "failed",
    phase: "Failed",
    nodeName: "ip-10-0-1-103.ec2.internal",
    containers: [
      {
        name: "payment-service",
        image: "octrix/payment-service:v2.5.0",
        status: "terminated",
        ready: false,
        restartCount: 5,
        cpuUsage: 0,
        memoryUsage: 0,
        ports: [{ name: "http", containerPort: 8080, protocol: "TCP" }],
      },
    ],
    restarts: 5,
    cpuUsage: 0,
    memoryUsage: 0,
    createdAt: "2024-01-18T09:15:00Z",
    labels: { app: "payment-service", version: "v2.5.0" },
    annotations: {},
    ownerReferences: [{ kind: "ReplicaSet", name: "payment-service-2a3b4c5d6", uid: "rs-4" }],
    ip: "10.244.2.23",
  },
  {
    id: "pod-5",
    name: "redis-cache-0",
    namespace: "production",
    status: "running",
    phase: "Running",
    nodeName: "ip-10-0-1-102.ec2.internal",
    containers: [
      {
        name: "redis",
        image: "redis:7.2-alpine",
        status: "running",
        ready: true,
        restartCount: 0,
        cpuUsage: 50,
        memoryUsage: 256,
        ports: [{ name: "redis", containerPort: 6379, protocol: "TCP" }],
      },
    ],
    restarts: 0,
    cpuUsage: 50,
    memoryUsage: 256,
    createdAt: "2024-01-17T12:00:00Z",
    labels: { app: "redis", role: "cache" },
    annotations: {},
    ownerReferences: [{ kind: "StatefulSet", name: "redis-cache", uid: "sts-1" }],
    ip: "10.244.1.10",
  },
  {
    id: "pod-6",
    name: "postgres-primary-0",
    namespace: "production",
    status: "running",
    phase: "Running",
    nodeName: "ip-10-0-1-103.ec2.internal",
    containers: [
      {
        name: "postgres",
        image: "postgres:15.4",
        status: "running",
        ready: true,
        restartCount: 0,
        cpuUsage: 320,
        memoryUsage: 1024,
        ports: [{ name: "postgres", containerPort: 5432, protocol: "TCP" }],
      },
    ],
    restarts: 0,
    cpuUsage: 320,
    memoryUsage: 1024,
    createdAt: "2024-01-16T08:00:00Z",
    labels: { app: "postgres", role: "primary" },
    annotations: {},
    ownerReferences: [{ kind: "StatefulSet", name: "postgres-primary", uid: "sts-2" }],
    ip: "10.244.2.5",
  },
];

export const mockServices: Service[] = [
  {
    id: "svc-1",
    name: "api-gateway",
    namespace: "production",
    type: "LoadBalancer",
    clusterIP: "10.96.0.10",
    externalIP: "52.23.145.67",
    ports: [{ name: "http", port: 80, targetPort: 8080, protocol: "TCP" }],
    selector: { app: "api-gateway" },
    endpoints: [{ ip: "10.244.1.15", port: 8080, nodeName: "ip-10-0-1-102.ec2.internal", ready: true }],
    createdAt: "2024-01-18T09:00:00Z",
  },
  {
    id: "svc-2",
    name: "user-service",
    namespace: "production",
    type: "ClusterIP",
    clusterIP: "10.96.0.20",
    ports: [{ name: "grpc", port: 9090, targetPort: 9090, protocol: "TCP" }],
    selector: { app: "user-service" },
    endpoints: [{ ip: "10.244.1.16", port: 9090, nodeName: "ip-10-0-1-102.ec2.internal", ready: true }],
    createdAt: "2024-01-18T09:05:00Z",
  },
  {
    id: "svc-3",
    name: "order-processor",
    namespace: "production",
    type: "ClusterIP",
    clusterIP: "10.96.0.30",
    ports: [{ name: "http", port: 8080, targetPort: 8080, protocol: "TCP" }],
    selector: { app: "order-processor" },
    endpoints: [{ ip: "10.244.2.22", port: 8080, nodeName: "ip-10-0-1-103.ec2.internal", ready: true }],
    createdAt: "2024-01-18T09:10:00Z",
  },
  {
    id: "svc-4",
    name: "redis-cache",
    namespace: "production",
    type: "ClusterIP",
    clusterIP: "10.96.0.40",
    ports: [{ name: "redis", port: 6379, targetPort: 6379, protocol: "TCP" }],
    selector: { app: "redis" },
    endpoints: [{ ip: "10.244.1.10", port: 6379, nodeName: "ip-10-0-1-102.ec2.internal", ready: true }],
    createdAt: "2024-01-17T12:00:00Z",
  },
  {
    id: "svc-5",
    name: "postgres",
    namespace: "production",
    type: "ClusterIP",
    clusterIP: "10.96.0.50",
    ports: [{ name: "postgres", port: 5432, targetPort: 5432, protocol: "TCP" }],
    selector: { app: "postgres" },
    endpoints: [{ ip: "10.244.2.5", port: 5432, nodeName: "ip-10-0-1-103.ec2.internal", ready: true }],
    createdAt: "2024-01-16T08:00:00Z",
  },
];

export const mockDeployments: Deployment[] = [
  {
    id: "deploy-1",
    name: "api-gateway",
    namespace: "production",
    replicas: 3,
    availableReplicas: 3,
    readyReplicas: 3,
    updatedReplicas: 3,
    strategy: "RollingUpdate",
    selector: { app: "api-gateway" },
    createdAt: "2024-01-18T09:00:00Z",
    conditions: [
      {
        type: "Available",
        status: "True",
        reason: "MinimumReplicasAvailable",
        message: "Deployment has minimum availability.",
        lastTransitionTime: "2024-01-18T09:05:00Z",
      },
    ],
  },
  {
    id: "deploy-2",
    name: "user-service",
    namespace: "production",
    replicas: 2,
    availableReplicas: 2,
    readyReplicas: 2,
    updatedReplicas: 2,
    strategy: "RollingUpdate",
    selector: { app: "user-service" },
    createdAt: "2024-01-18T09:05:00Z",
    conditions: [
      {
        type: "Available",
        status: "True",
        reason: "MinimumReplicasAvailable",
        message: "Deployment has minimum availability.",
        lastTransitionTime: "2024-01-18T09:10:00Z",
      },
    ],
  },
  {
    id: "deploy-3",
    name: "order-processor",
    namespace: "production",
    replicas: 4,
    availableReplicas: 4,
    readyReplicas: 4,
    updatedReplicas: 4,
    strategy: "RollingUpdate",
    selector: { app: "order-processor" },
    createdAt: "2024-01-18T09:10:00Z",
    conditions: [
      {
        type: "Available",
        status: "True",
        reason: "MinimumReplicasAvailable",
        message: "Deployment has minimum availability.",
        lastTransitionTime: "2024-01-18T09:15:00Z",
      },
    ],
  },
  {
    id: "deploy-4",
    name: "payment-service",
    namespace: "production",
    replicas: 2,
    availableReplicas: 1,
    readyReplicas: 1,
    updatedReplicas: 2,
    strategy: "RollingUpdate",
    selector: { app: "payment-service" },
    createdAt: "2024-01-18T09:15:00Z",
    conditions: [
      {
        type: "Available",
        status: "False",
        reason: "MinimumReplicasUnavailable",
        message: "Deployment does not have minimum availability.",
        lastTransitionTime: "2024-01-20T14:30:00Z",
      },
    ],
  },
];

export const mockNamespaces: Namespace[] = [
  {
    id: "ns-1",
    name: "production",
    status: "Active",
    labels: { environment: "production" },
    createdAt: "2024-01-15T10:30:00Z",
    podCount: 45,
    serviceCount: 12,
  },
  {
    id: "ns-2",
    name: "staging",
    status: "Active",
    labels: { environment: "staging" },
    createdAt: "2024-01-15T10:30:00Z",
    podCount: 28,
    serviceCount: 8,
  },
  {
    id: "ns-3",
    name: "monitoring",
    status: "Active",
    labels: { environment: "system" },
    createdAt: "2024-01-15T10:30:00Z",
    podCount: 15,
    serviceCount: 5,
  },
  {
    id: "ns-4",
    name: "kube-system",
    status: "Active",
    labels: {},
    createdAt: "2024-01-15T10:30:00Z",
    podCount: 22,
    serviceCount: 4,
  },
];

export const mockHealingRules: HealingRule[] = [
  {
    id: "rule-1",
    name: "Auto-restart CrashLoopBackOff Pods",
    description: "Automatically restart pods that enter CrashLoopBackOff state after 3 consecutive failures",
    enabled: true,
    trigger: {
      type: "pod-crash",
      conditions: [
        { metric: "restart_count", operator: ">=", value: 3, duration: "5m" },
      ],
      operator: "AND",
    },
    action: {
      type: "restart-pod",
      parameters: { gracePeriodSeconds: 30 },
    },
    cooldownSeconds: 300,
    lastTriggered: "2024-01-20T14:35:00Z",
    triggerCount: 12,
    createdAt: "2024-01-16T10:00:00Z",
  },
  {
    id: "rule-2",
    name: "Scale on High CPU",
    description: "Scale deployment when CPU usage exceeds 80% for 5 minutes",
    enabled: true,
    trigger: {
      type: "high-cpu",
      conditions: [
        { metric: "cpu_usage_percent", operator: ">", value: 80, duration: "5m" },
      ],
      operator: "AND",
    },
    action: {
      type: "scale-deployment",
      parameters: { scaleBy: 2, maxReplicas: 10 },
    },
    cooldownSeconds: 600,
    lastTriggered: "2024-01-19T22:15:00Z",
    triggerCount: 5,
    createdAt: "2024-01-16T10:30:00Z",
  },
  {
    id: "rule-3",
    name: "Cordon Node on Memory Pressure",
    description: "Cordon node when memory usage exceeds 90%",
    enabled: true,
    trigger: {
      type: "high-memory",
      conditions: [
        { metric: "memory_usage_percent", operator: ">", value: 90, duration: "3m" },
      ],
      operator: "AND",
    },
    action: {
      type: "cordon-node",
      parameters: {},
    },
    cooldownSeconds: 1800,
    triggerCount: 2,
    createdAt: "2024-01-16T11:00:00Z",
  },
  {
    id: "rule-4",
    name: "OOM Kill Recovery",
    description: "Restart pods killed due to OOM and notify team",
    enabled: false,
    trigger: {
      type: "oom-killed",
      conditions: [
        { metric: "oom_killed", operator: "==", value: 1, duration: "0s" },
      ],
      operator: "AND",
    },
    action: {
      type: "restart-pod",
      parameters: { gracePeriodSeconds: 0, notify: true },
    },
    cooldownSeconds: 120,
    triggerCount: 0,
    createdAt: "2024-01-17T09:00:00Z",
  },
];

export const mockHealingEvents: HealingEvent[] = [
  {
    id: "event-1",
    ruleId: "rule-1",
    ruleName: "Auto-restart CrashLoopBackOff Pods",
    timestamp: "2024-01-20T14:35:00Z",
    status: "success",
    targetResource: "payment-service-2a3b4c5d6-g7h8i",
    targetNamespace: "production",
    action: "restart-pod",
    details: "Pod restarted successfully after 3 consecutive failures",
    duration: 2500,
  },
  {
    id: "event-2",
    ruleId: "rule-2",
    ruleName: "Scale on High CPU",
    timestamp: "2024-01-19T22:15:00Z",
    status: "success",
    targetResource: "order-processor",
    targetNamespace: "production",
    action: "scale-deployment",
    details: "Scaled deployment from 2 to 4 replicas",
    duration: 5200,
  },
  {
    id: "event-3",
    ruleId: "rule-1",
    ruleName: "Auto-restart CrashLoopBackOff Pods",
    timestamp: "2024-01-19T18:20:00Z",
    status: "success",
    targetResource: "user-service-5c7d8e9f1-a3b2c",
    targetNamespace: "production",
    action: "restart-pod",
    details: "Pod restarted successfully",
    duration: 1800,
  },
  {
    id: "event-4",
    ruleId: "rule-3",
    ruleName: "Cordon Node on Memory Pressure",
    timestamp: "2024-01-18T03:45:00Z",
    status: "success",
    targetResource: "ip-10-0-1-103.ec2.internal",
    targetNamespace: "",
    action: "cordon-node",
    details: "Node cordoned due to memory pressure (92% usage)",
    duration: 800,
  },
];

export const mockSimulationScenarios: SimulationScenario[] = [
  {
    id: "scenario-1",
    name: "Random Pod Failure",
    description: "Randomly terminate pods to test resilience and auto-healing capabilities",
    type: "pod-failure",
    parameters: {
      targetNamespace: "production",
      podSelector: { app: "api-gateway" },
      killCount: 1,
      interval: 60,
    },
    duration: 300,
    createdAt: "2024-01-17T10:00:00Z",
  },
  {
    id: "scenario-2",
    name: "Node Drain Simulation",
    description: "Simulate node failure by draining a worker node",
    type: "node-failure",
    parameters: {
      targetNode: "ip-10-0-1-103.ec2.internal",
      gracePeriod: 30,
    },
    duration: 600,
    createdAt: "2024-01-17T11:00:00Z",
  },
  {
    id: "scenario-3",
    name: "CPU Stress Test",
    description: "Inject CPU stress to test horizontal pod autoscaling",
    type: "cpu-stress",
    parameters: {
      targetNamespace: "production",
      podSelector: { app: "order-processor" },
      cpuLoad: 90,
      workers: 4,
    },
    duration: 180,
    createdAt: "2024-01-17T12:00:00Z",
  },
  {
    id: "scenario-4",
    name: "Network Latency Injection",
    description: "Add network latency between services to test timeout handling",
    type: "latency-injection",
    parameters: {
      targetNamespace: "production",
      sourceSelector: { app: "api-gateway" },
      destinationSelector: { app: "user-service" },
      latencyMs: 500,
      jitterMs: 100,
    },
    duration: 120,
    createdAt: "2024-01-17T13:00:00Z",
  },
];

export const mockSimulationRuns: SimulationRun[] = [
  {
    id: "run-1",
    scenarioId: "scenario-1",
    scenarioName: "Random Pod Failure",
    status: "completed",
    startTime: "2024-01-20T10:00:00Z",
    endTime: "2024-01-20T10:05:00Z",
    affectedResources: ["api-gateway-7d8f9c6b5-x2k4m"],
    metrics: [
      { name: "Recovery Time", before: 0, during: 0, after: 12, unit: "seconds" },
      { name: "Request Success Rate", before: 99.9, during: 95.2, after: 99.8, unit: "%" },
      { name: "P99 Latency", before: 45, during: 320, after: 52, unit: "ms" },
    ],
  },
  {
    id: "run-2",
    scenarioId: "scenario-3",
    scenarioName: "CPU Stress Test",
    status: "completed",
    startTime: "2024-01-19T14:00:00Z",
    endTime: "2024-01-19T14:03:00Z",
    affectedResources: ["order-processor-8e9f0a1b2-d4e5f"],
    metrics: [
      { name: "CPU Usage", before: 35, during: 92, after: 38, unit: "%" },
      { name: "Replica Count", before: 2, during: 4, after: 4, unit: "" },
      { name: "Request Queue Length", before: 5, during: 45, after: 8, unit: "" },
    ],
  },
];

export const mockAlerts: Alert[] = [
  {
    id: "alert-1",
    severity: "critical",
    title: "Pod CrashLoopBackOff",
    message: "Pod payment-service-2a3b4c5d6-g7h8i is in CrashLoopBackOff state",
    resource: "payment-service-2a3b4c5d6-g7h8i",
    namespace: "production",
    timestamp: "2024-01-20T14:30:00Z",
    acknowledged: false,
  },
  {
    id: "alert-2",
    severity: "warning",
    title: "High Memory Usage",
    message: "Node ip-10-0-1-102.ec2.internal memory usage at 85%",
    resource: "ip-10-0-1-102.ec2.internal",
    namespace: "",
    timestamp: "2024-01-20T13:45:00Z",
    acknowledged: false,
  },
  {
    id: "alert-3",
    severity: "warning",
    title: "Deployment Replica Mismatch",
    message: "Deployment payment-service has 1/2 replicas available",
    resource: "payment-service",
    namespace: "production",
    timestamp: "2024-01-20T14:32:00Z",
    acknowledged: false,
  },
  {
    id: "alert-4",
    severity: "info",
    title: "Auto-healing Triggered",
    message: "Rule 'Auto-restart CrashLoopBackOff Pods' triggered for payment-service",
    resource: "payment-service-2a3b4c5d6-g7h8i",
    namespace: "production",
    timestamp: "2024-01-20T14:35:00Z",
    acknowledged: true,
  },
];

export const mockCpuMetrics = generateTimeSeriesData(6, 65, 20);
export const mockMemoryMetrics = generateTimeSeriesData(6, 72, 15);
export const mockNetworkMetrics = generateTimeSeriesData(6, 45, 30);
export const mockPodCountMetrics = generateTimeSeriesData(6, 156, 10);
